{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 爬虫的概念\n",
    "- 爬虫是模拟浏览器发送请求，获取响应\n",
    "\n",
    "### 爬虫的流程\n",
    "- url --->发送请求，获取响应--->提取数据--->保存\n",
    "- 发送请求，获取响应 --->提取url\n",
    "\n",
    "#### 爬虫要根据当前url地址的响应为准，当前url地址的elements的内容和url的响应不一样\n",
    "### 页面上的数据在哪里\n",
    "- 当前url地址对应的响应中\n",
    "- 其他url地址对应的响应中\n",
    "+ ajax请求中\n",
    "+ js生成:（1）部分数据在响应中 (2)全部通过js生成\n",
    "\n",
    "#### requests中解决编码的方法\n",
    "+ response.content.decode()\n",
    "+ response.content.decode(\"gbk\")\n",
    "+ response.text\n",
    "\n",
    "#### 发送带header请求\n",
    "+ header形式:字典\n",
    "+ headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36\"}\n",
    "+ 用法:request.get(url,headers=headers)\n",
    "\n",
    "#### 发送带参数的请求\n",
    "+ 参数的形式:字典\n",
    "+ kw = {'wd':'长城'}\n",
    "+ 用法:request.get(url,params=kw\n",
    "\n",
    "#### 发送POST请求\n",
    "+ 用到POST请求的地方\n",
    "+ 1.登陆注册（POST比GET更安全）\n",
    "+ 2.需要传输大文本内容的时候（POST请求对数据长度没有要求）\n",
    "+ 爬虫也需要在这两个地方取模拟浏览器发送的post请求\n",
    "\n",
    "#### 发送POST请求\n",
    "+ 用法:resopnse = requests.post(\"http://www.baidu.com/\",data=data,headers=headers)\n",
    "+ data形式:字典\n",
    "\n",
    "#### 使用代理\n",
    "+ 用法:requests.get(\"http://www.baidu.com\",proxies=proxies)\n",
    "+ proxies的形式:字典\n",
    "+ proxies = {\n",
    "    \"http\":\"http://12.34.56.79:9527\",\n",
    "    \"https\":\"https://12.34.56.79:9527\"\n",
    "    }\n",
    "    \n",
    "#### cookie和session的区别(爬虫带上 可以请求到登陆之后的页面)\n",
    "+ cookie数据存放在客户的浏览器上，session数据放在服务器上。\n",
    "+ cookie不是很安全，明文\n",
    "+ session会在一定时间内保存在服务器上。当访问增多，会比较占用服务器的性能\n",
    "+ 单个cookie保存的数据不能超过4k,很多浏览器一般限制一个站点最多保存20个cookie.\n",
    "\n",
    "#### 处理cookies、session请求\n",
    "+ requests提供了一个叫做session类，来实现客户端和服务的的会话保持\n",
    "+ 使用方法;\n",
    "+ 1.实例化一个session对象\n",
    "+ 2.让session发送get或者post请求\n",
    "\n",
    "+ session = requests.session()\n",
    "+ response = session.get(url,headers)\n",
    "\n",
    "#### response.text 和 response.content的区别\n",
    "+ response.text\n",
    "+ 类型: str\n",
    "+ 解码类型:根据HTTP头部对响应的编码做出有根据的推测，推测出的文本编码\n",
    "+ 修改编码方式:response.encoding = \"gbk\"<br><br>\n",
    "\n",
    "+ response.content\n",
    "+ 类型: bytes\n",
    "+ 解码类型:没有\n",
    "+ 修改编码方式:response.content.dencode = \"utf8\"<br><br>\n",
    "+ 推荐response.content.dencode()获取响应的html页面\n",
    "\n",
    "#### requets小技巧\n",
    "+ 1.requests.util.dict_from_cookiejar 把cookie对象转化为字典\n",
    "+ 2.请求SSL证书验证\n",
    "+  response = requests.get(\"\")   \n",
    "+ 3.设置超时\n",
    "+ response = request.get(url,timeout=10)\n",
    "+ 4.配合状态码判断是否请求成功\n",
    "+ assert response.status_code == 200\n",
    "\n",
    "#### 寻找登陆的post地址\n",
    "+ 在from表单中寻找action对应的url地址\n",
    "+ post数据是input标签中name的值作为键，正真的用户密码作为值的字典，post的url地址就是action对应的url地址\n",
    "\n",
    "#### 抓包\n",
    "+ 勾选perserve log按钮,防止页面跳转找不到url\n",
    "+ 寻找post数据，确定参数\n",
    "+ 参数不会变，直接用\n",
    "+ 参数会变：（1）参数在当前响应中 （2）通过js生成\n",
    "\n",
    "#### 定位想要的js\n",
    "+ 选择会触发js的事件按钮，点击event listener，找到js的位置\n",
    "+ 通过chrome中的search all file来搜索url中的关键字\n",
    "+ 添加断点的方式查看js的操作\n",
    "\n",
    "#### 安装第三方模块\n",
    "+ pip install retrying\n",
    "+ 下载源码解码，进入解压后目录，\"\"\"python setup.py install\"\"\"\n",
    "+ '***.py' 安装方法 'pip install ***.whl'\n",
    "\n",
    "#### json使用注意点\n",
    "+ json中的字符都是双引号引起来的\n",
    "+ eval:能实现简单的字符串和python类型的转化\n",
    "+ replace:把单引号替换为双引号\n",
    "+ 往一个文件中写入多个json串,不再是一个json串，不能直接读取\n",
    "+ 一行写一个json串，安装行来读取\n",
    "\n",
    "#### 常用正则表达式\n",
    "+ re.comple(编译)\n",
    "+ pattern.match(从头找一个)\n",
    "+ pattern.search(找一个)\n",
    "+ pattern.findall(找所有)\n",
    "+ pattern.sub(替换)<br><br>\n",
    "\n",
    "+ re.findall(\"a(.*?)b\",\"str\"),能够返回括号中的内容，括号前后的内容起到定位和过滤的效果\n",
    "+ 原始字符串r,带匹配字符串中有反斜杠的时候，使用r能够忽视反斜杠带来的转移效果\n",
    "+ 点号默认情况匹配不到'\\n'\n",
    "+ '\\s'能够匹配空白字符，不仅仅包含空格、\\t \\r \\n\n",
    "\n",
    "#### xpath重点\n",
    "+ 获取文本 a/text()获取a下的文本  a//text()获取a下的所有文本 '//a[text()='下一页']'选择文本为下一页的a标签\n",
    "+ '@'获取属性   'a/@href'\n",
    "+ //（1）在xpath开始的时候表示从当前html中任意位置开始选择 （2）li/a表示li下的任何一个标签\n",
    "#### xpath包含\n",
    "+ //div[contains(@class,'i')] \n",
    "\n",
    "#### lxml使用注意点\n",
    "+ lxml能够修正HTML代码，但是可能会改错\n",
    "+ 使用etree.tostring观察修改之后的html的样子，根据修改之后的html字符串写xpath\n",
    "+ from lxml import etree\n",
    "+ element = etree.HTML(bytes,str) #把字符串转化为element对象\n",
    "+ etree.tostring(element) #把element对象转化为字符串\n",
    "+ element.xpath(\"xpath_str\")\n",
    "\n",
    "#### 提取页面数据\n",
    "+ 1.先分组，选取一个包含分组标签的列表\n",
    "+ 2.遍历，对其中每一组进行数据的提取，不会造成数据的对应错乱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 判断请求是否成功\n",
    "\"\"\"python\n",
    "assert response.status_code == 200\n",
    "\"\"\"\n",
    "\n",
    "#### url编码\n",
    "+ https://www.baidu.com/s?wd=%E4%BC%A0%E6%99%BA%E5%8D%9A%E5%AE%A2\n",
    "\n",
    "#### 使用代理IP\n",
    "+ 准备ip池，随机选择一个ip来使用\n",
    "+ 如何随机选择代理ip\n",
    "+ {\"ip\":ip,\"times\":0}\n",
    "+ [{},{},{},{}],对这个ip列表进行排序，安装使用次数进行排序\n",
    "+ 选择使用次数较少的10个ip,从中随机选择一个\n",
    "+ 检查ip的可用性\n",
    "+ 使用requests添加超时参数,判断ip地址质量\n",
    "+ 在线代理ip质量检测的网站\n",
    "\n",
    "#### 携带cookie请求\n",
    "+ 携带一堆cookie进行请求，把cookie组成cookie池\n",
    "\n",
    "#### 使用requets提供的session来请求登陆之后的网站思路\n",
    "+ 实例化session\n",
    "+ 先使用session发送请求，登陆对应网站，把cookie保持在session中\n",
    "+ 再使用session请求登陆之后才能访问网站，session能够自动携带登陆成功时保持在其中的cookie,进行请求\n",
    "\n",
    "#### 不发送post请求，使用cookie获取登陆后的页面\n",
    "+ cookie过期时间很长的网站\n",
    "+ 在cookie过期之前能够拿到所有的数据\n",
    "+ 配合其他程序一起使用，其他程序专门获取cookie，当前程序专门请求页面\n",
    "\n",
    "#### 获取登陆后页面的三种方式\n",
    "+ 实例化session,使用session发送post请\n",
    "+ headers中添加cookie键，值为cookie字符串\n",
    "+ 在请求方法中添加cookies参数，接收字典形式的cookie。字典形式的cookie中的键是cookie的name对应的值，值是cookie的value对应的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
